# URL Phishing Detection - Ensemble Deep Learning Framework

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.19.0-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

A robust, production-ready ensemble deep learning framework for detecting phishing URLs using advanced neural network architectures with comprehensive statistical validation.

âœ¨ Key Features

Ensemble Learning

CNNâ€“BiLSTM base model

Multi-scale CNN architecture

Attention-based neural model

Wide (high-capacity) architecture

Feature Engineering

Character-level URL tokenization

Vectorized numerical URL features

Fold-isolated feature extraction (no data leakage)

Evaluation & Validation

Stratified K-fold cross-validation (default: 10-fold)

Accuracy, Precision, Recall, F1-score, AUC-ROC

Statistical significance testing (McNemar, t-test, Wilcoxon, ANOVA, Cohenâ€™s d)

Research-Oriented Design

Fully modular codebase

Deterministic training via fixed random seeds

Clear separation of data processing, modeling, and evaluation



## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Setup

1. Clone the repository:
```
git clone https://github.com/DenizKaya18/phishing-url-detection.git
cd url-phishing-detection
```

2. Install dependencies:
```
pip install -r requirements.txt
```

### Requirements

```
tensorflow==2.19.0
pandas==2.2.2
numpy==2.0.2
scikit-learn==1.6.1
wordsegment==1.3.1
tldextract==5.3.1
matplotlib==3.10.0
seaborn==0.13.2
psutil==5.9.5
```

## âš¡ Quick Start

### Basic Usage

```
from preprocessing import prepare_data_from_raw
from ensemble_classifier import OptimizedEnsembleURLClassifierCV

# Load dataset
X_train, X_test, y_train, y_test, tokenizer, max_len, vocab = \
    prepare_data_from_raw("data/dataset.txt")

# Initialize ensemble
classifier = OptimizedEnsembleURLClassifierCV(
    n_models=4,
    n_folds=10,
    random_seeds=[42, 123, 456, 789]
)

classifier.tokenizer = tokenizer
classifier.max_len = max_len
classifier.vocab_size = vocab

# Cross-validation
classifier.cross_validate_ensemble(X_train, y_train, epochs=15)

# Final training
classifier.train_final_ensemble(
    X_train, y_train, X_test, y_test, epochs=15
)

```

## ğŸ“ Project Structure

```
url-phishing-detection/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ ensemble_classifier.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ statistical_tests.py
â”‚	â”œâ”€â”€ feature_extraction.py
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ README.md        ğŸ‘ˆ dataset description and source
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ mendeley_urls.txt
â”‚
â”œâ”€â”€ results/  # Evaluation outputs (auto-generated)
â”œâ”€â”€ models/   # Saved models (auto-generated)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

```



### Dataset

This study uses a publicly available phishing URL dataset from Mendeley Data:

Source: https://data.mendeley.com/datasets/vfszbj9b36/1

Original labels: legitimate, phishing

Encoded labels:

0 â†’ legitimate

1 â†’ phishing

Label encoding was performed without altering class semantics or sample distribution.

Further details are provided in data/README.md.



### Training Pipeline

The `main.py` script executes a complete training pipeline:

1. **Data Preprocessing**: Load, tokenize, and split data
2. **Cross-Validation**: Train and evaluate models using K-fold CV
3. **Final Training**: Train ensemble on full training set
4. **Statistical Testing**: Validate model performance significance
5. **Results Summary**: Display comprehensive metrics

### Custom Configuration

```python
classifier, stats = main(
    data_file="data/dataset.txt",
    test_size=0.2,          # Test set proportion
    n_folds=10,             # Number of CV folds
    epochs=15,              # Training epochs
    batch_size=512          # Batch size
)
```

## ğŸ—ï¸ Model Architectures

### 1. Base Model (CNN-BiLSTM)
- **Embedding**: 64-dimensional character embeddings
- **CNN**: 64 filters, kernel size 3, L2 regularization
- **BiLSTM**: 32 units per direction, dropout 0.3
- **Dense**: Two layers (64â†’32 units) with batch normalization

### 2. Multi-CNN Model
- Multiple convolutional branches (kernel sizes: 3, 5)
- Parallel feature extraction at different scales
- BiLSTM for sequence modeling
- Feature concatenation and fusion

### 3. Attention Model
- Custom attention mechanism for character importance
- CNN for local pattern detection
- Attention-weighted feature aggregation
- Dense classification layers

### 4. Wide Model
- Increased capacity (64 CNN filters, 64 BiLSTM units)
- Enhanced feature representation
- Suitable for complex pattern recognition
- Balanced regularization

## ğŸ” Feature Extraction

- Character-level URL sequences (deep models)

- Vectorized numerical features (URL structure-based)

- Fold-isolated feature computation to prevent information leakage

- Standardized scaling applied only on training folds

## ğŸ“Š Evaluation Metrics

The framework computes comprehensive metrics:

- **Accuracy**: Overall classification accuracy
- **Precision**: Positive predictive value
- **Recall (Sensitivity)**: True positive rate
- **F1-Score**: Harmonic mean of precision and recall
- **Specificity**: True negative rate
- **FPR**: False positive rate
- **FNR**: False negative rate
- **AUC-ROC**: Area under the ROC curve
- **Confusion Matrix**: Detailed classification breakdown



## ğŸ“ˆ Statistical Tests

### Implemented Tests

1. **McNemar's Test**
   - Compares paired predictions
   - Tests for significant differences between models

2. **Paired t-Test**
   - Compares mean performance across folds
   - Parametric test for normally distributed data

3. **Wilcoxon Signed-Rank Test**
   - Non-parametric alternative to t-test
   - Robust to non-normal distributions



### Running Statistical Tests

```python
from statistical_tests import run_statistical_tests

# After training ensemble
statistical_results = run_statistical_tests(classifier)
```

## âš™ï¸ Configuration

### Model Hyperparameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `n_models` | 4 | Number of models in ensemble |
| `n_folds` | 10 | Cross-validation folds |
| `epochs` | 15 | Training epochs per model |
| `batch_size` | 512 | Training batch size |
| `learning_rate` | 0.008 | Adam optimizer learning rate |
| `max_len` | Auto (95%ile) | Maximum sequence length |
| `embedding_dim` | 64 | Character embedding dimension |

### Training Options

```python
# Enable mixed precision training (automatic)
# Supports GPU acceleration
# Dynamic loss scaling for numerical stability

# Callbacks (built-in):
# - EarlyStopping (patience=5)
# - ReduceLROnPlateau (patience=3)
```

### Output Example

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    URL PHISHING DETECTION - ENSEMBLE DEEP LEARNING                    
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‚ STEP 1: Data Preprocessing
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Data loaded successfully
  Vocabulary size: 98
  Max sequence length: 167
  Training samples: 8000
  Test samples: 2000

ğŸ”¬ STEP 2: Initialize Ensemble Classifier
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“Š STEP 3: Cross-Validation Training
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“ˆ Cross-Validation Results:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  base        : 0.9650 (Â± 0.0089)
  multi_cnn   : 0.9625 (Â± 0.0095)
  attention   : 0.9638 (Â± 0.0092)
  wide        : 0.9668 (Â± 0.0085)
  Ensemble    : 0.9725 (Â± 0.0078)

âœ… TRAINING COMPLETED SUCCESSFULLY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Deniz Kaya**




